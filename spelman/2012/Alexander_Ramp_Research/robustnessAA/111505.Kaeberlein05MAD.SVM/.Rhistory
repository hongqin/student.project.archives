pred
    # Check accuracy:
     table(pred, y)  #this is 100% correct as expected. 
pred
pred[1]
pred[2]
str(pred);
str(y);
     # Check accuracy:
     table(factor(pred), y)
cbind(pred,y);
cbind(pred,y);
cbind( as.character(pred), as.character(y));
table(as.character(pred), as.character(y));
help(table);
yy = as.character(y)
predpred = as.character(pred)
yy
predpred
str(predpred);
y
str(x)
x
y
x = kg[, seq(9,181)]
#x[ is.na(x) ] = 0;
#xpca = pca(x);
y = factor( kg[,5]);
model = svm( x, y);
model
help(model);
help(svm);
model$gamma
model$gamma * 173
plot(model)
print(model);
summary(model);
x = kg[, seq(9,181)]
#x[ is.na(x) ] = 0;
#xpca = pca(x);
y = factor( kg[,5]);
model = svm( x, y);
  pred <- fitted(model)
pred
model
y
x = kg[, seq(9,181)]
#x[ is.na(x) ] = 0;
xpca = pca(x);
x
x[ is.na(x) ] = 0;
xpca = pca(x);
xpca
str(xpca);
xpca$pcs
help(pca);
str(xpca$pcs)
str(x);
model = svm( xpca, y);
y
model = svm( xpca$pcs, y);
model
   pred <- fitted(model)
pred
table( pred, y);
model = svm( xpca$pcs[,seq(1,5), y);
     # test with train data
     pred <- predict(model, x)
     # (same as:)
     pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
y = factor( kg[,5]);
model = svm( xpca$pcs[,seq(1,2), y);
     # test with train data
     pred <- predict(model, x)
     # (same as:)
     pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
model = svm( xpca$pcs[,seq(1,2)], y);
 pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
pred
y
y = factor( kg[,5]);
model = svm( xpca$pcs[,seq(1,5)], y);
     # test with train data
     pred <- predict(model, x)
     # (same as:)
     pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
y = factor( kg[,5]);
model = svm( xpca$pcs[,seq(1,10)], y);
     # test with train data
     pred <- predict(model, x)
     # (same as:)
     pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
model = svm( xpca$pcs, y);
     # test with train data
#     pred <- predict(model, x)
     # (same as:)
     pred <- fitted(model)
     # Check accuracy:
     table(factor(pred), y)  #Ha, this is 100% correct.
gasch = read.table("gasch.tab", sep="\t" );
gasch = read.table("gasch00.tab", sep="\t" );
gasch = read.table("gasch00.tab", sep="\t", header=T );
gash[6153,]
gasch[6153,]
help(read.table);
gasch = read.csv("gasch00.tab", sep="\t", header=T );
gasch[6153,]
str(gasch);
gasch[6152,]
str(gasch)
sub.g = gasch[, seq(4,176)]
sub.g[1,]
str(sub.g)
xpca = pca(sub.g );
sub.g[ is.na(sub.g) ] = 0;
xpca = pca(sub.g );
gpca = pca(sub.g );
str(gpca);
str(gpca$pcs);
gpca$pcs[1:5, 1:2]
gpca$pcs[1:5, 1:10]
gpca$pcs[1:5, 1:20]
gpca$d[1:5, 1:20]
gpca$d
gpca$d[50,50]
gpca$d[1,1]
gpca$d[150,150]
gpca$d[2,2]
gpca$d[3,3]
gpca$d[4,4]
gpca$d[10,10]
row.names(gpca) = gasch[,1]
gasch[1:5,1]
row.names(gpca$pcs) = gasch[,1]
gpca$pcs[1:5,1:5]
row.names(sub.g) = gasch[,1]
gpca = pca(sub.g );
gpca$pcs[1:5,1:5]
str(gpca$pcs)
row.names(gpca$pcs) = gasch[,1]
gpca$pcs[1:5,1:5]
write.table(gpca$pcs, "gasch.pca.tab" col.name=F, sep="\t", quote=F);
write.table(gpca$pcs, "gasch.pca.tab", col.name=F, sep="\t", quote=F);
tb = read.table("kaeberlein.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
tb
gpcs = data.frame( cbind( as.character(gasch[,1], gpac$pcs);
gpcs = data.frame( cbind( as.character(gasch[,1], gpac$pcs) );
gpcs = data.frame( cbind( as.character(gasch[,1]), gpac$pcs) );
gpcs = data.frame( cbind( as.character(gasch[,1]), gpca$pcs) );
str(gpcs);
row.names( gpcs)
grep( row.names(gpcs), k.orf ) 
tb = read.table("kaeberlein.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
k.orf = as.character( tb$orf );
grep( row.names(gpcs), k.orf ) 
k.orf
selected.rows = c( selected.rows, grep( row.names(gpcs), k.orf[i] ) )
selected.rows = 0;
selected.rows = c( selected.rows, grep( row.names(gpcs), k.orf[i] ) )
i =1
selected.rows = c( selected.rows, grep( row.names(gpcs), k.orf[i] ) )
k,orf[i]
k.orf[i]
grep( row.names(gpcs), "YBL103C");
row.names(gpcs);
selected.rows = c( selected.rows, grep( gpcs[,1], k.orf[i] ) )
gpcs[,1]
k.orf
gpcs[,1] = as.character( gpcs[,1])
grep( gpcs[,1], k.orf[i] ) 
gpcs[ "YBL103"]
gpcs[ "YBL103",]
gpcs[ "YBL103",1:5]
gpcs[ k.orf, 1:2]
str(tb);
gpcs[ k.orf, 1:2] # test the selection, good
y = factor( tb$score )
model = svm( gpcs[ k,orf, 2:41, y);
model = svm( gpcs[ k,orf, 2:41], y);
model = svm( gpcs[ k.orf, 2:41], y);
model = svm( gpcs[ k.orf, seq(2,41)], y);
seq(2,41);
gpcs[k.orf, seq(2,41)]
y = factor( tb$score )
x = gpcs[ k.orf, seq(2,41)]
model = svm( x, y);
x
summary(x);
str(x)
x = as.numeric( gpcs[ k.orf, seq(2,41)] )
gpcs = data.frame( cbind( gasch[,1], gpac$pcs);
gpcs = data.frame( cbind( gasch[,1], gpac$pcs) );
gpcs = data.frame( cbind( gasch[,1], gpca$pcs) );
str(gpcs);
gpcs = data.frame( gpca$pcs) );
gpcs = data.frame( gpca$pcs) ;
gpcs[1:5,]
gpcs[ k.orf, 1:2] # test the selection, good
gpcs[ k.orf, 1:2] # test the selection, good
y = factor( tb$score )
x = gpcs[k.orf, 1:40]
model = svm( x, y);
model
 pred <- fitted(model)
 table(factor(pred), y)  #Ha, this is 100% correct.
table(pred, y)
     table( pred, y)  #Ha, this is 100% correct.
     pred <- predict(model, x)
pred
 pred.gasch = predict(model, gpcs);
tb
y = factor( tb$score )
x = gpcs[k.orf, 1:43]
model = svm( x, y);
     # test with train data
     pred <- predict(model, x)
 # Check accuracy:
     table( pred, y)  #Ha, this is 100% correct.
    table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
pred.gasch
pred.gasch[ pred.gasch=="increase"]
pred.gasch[ pred.gasch=="decrease"]
tb = read.table("kaeberlein.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
hist(tb$arls/26.5 )
#decide to use 20% as cutoff 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.2 ] = "increase";
tb$score[ (tb$arls/26.5)<0.8 ] = "decrease";
factor(tb$score);
#decide to use 10% as cutoff 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.1 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
tb
str(tb);
tb[tb$score=="increase"]
tb[tb$score="increase"]
tb$orf[tb$score="increase"]
tb$orf[tb$score=="increase"]
tb$orf[tb$score=="decrease"]
summary(tb);
tb$orf[tb$score=="moderate"]
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
 pred.gasch[ pred.gasch=="decrease"]
d =  pred.gasch[ pred.gasch=="decrease"]
summary(d);
summary(pred.gasch);
#### try again
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1. ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
#### try again
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1. ] = "increase";
tb$score[ (tb$arls/26.5)<0.85 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); #shit 4573 decrease genes, only 5 increase genes from training set.
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.05 ] = "increase";
tb$score[ (tb$arls/26.5)<0.85 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); 
summary(tb$score);
d = tb$score
summary(d);
summary(factor( tb$score) );
summary(pred.gasch); 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.08 ] = "increase";
tb$score[ (tb$arls/26.5)<0.85 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.07 ] = "increase";
tb$score[ (tb$arls/26.5)<0.85 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); 
#### try again
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.075 ] = "increase";
tb$score[ (tb$arls/26.5)<0.85 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); 
pred.gasch[ pred.gasch=="increase"]
gpcs[ pred.gasch=="increase",1]
str(gpcs)
gpcs[1:5,]
row.name(gpcs[ pred.gasch=="increase",1])
row.names(gpcs[ pred.gasch=="increase",1])
row.names(gpcs);
n = row.names(gpcs);
n[ pred.gasch=="increase"]
plus.orf = n[ pred.gasch=="increase"]
gasch[1:5,1:5]
row.names(gasch) = gasch[,1]
gasch[plus.orf]
summary(pred.gasch); 
n = row.names(gpcs);
plus.orf = n[ pred.gasch=="increase"]
gasch[plus.orf,1:5]
gasch[plus.orf,1:2]
gasch[plus.orf, 2]
write.csv( gasch[plus.orf, 2], "111505.predicted.rls.extension.orfs" , quote=F);
write.csv( gasch[plus.orf, 2], "111505.predicted.rls.extension.orfs.tab" , quote=F);
write.csv( tb, "kaeberlein.2.tab", quote=F, col.names=F);
write.csv( tb, "kaeberlein.2.tab", quote=F, col.names=F, sep="\t");
write.table( tb, "kaeberlein.2.tab", quote=F, col.names=F, row.names=F,sep="\t");
write.table( gasch[plus.orf, 2], "111505.predicted.rls.extension.orfs.tab" , quote=F, row.name=F,col.names=F);
ls();
library(e1071)
library(pcurves);
library(e1071)
library(pcurves);
library(pcurve);
stein = read.csv("steinmetz.pca.tab", sep="\t", header=T );
str(stein);
tb = read.table("kaeberlein.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
k.orf = as.character( tb$orf );
k.orf
tb
sub.s[ k.orf, 1:2] # test the selection, good
row.names(stein) = stein[,1]
sub.s = stein[, seq(2,26)]
row.names(sub.s) = stein[,1]
sub.s[1:2,]
stein = read.csv("steinmetz.pca.tab", sep="\t", header=F );
row.names(stein) = stein[,1]
sub.s = stein[, seq(2,26)]
row.names(sub.s) = stein[,1]
tb = read.table("kaeberlein.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
k.orf = as.character( tb$orf );
sub.s[ k.orf, 1:2] # test the selection, good
summary( sub.s[ k.orf, 1:2] ) # test the selection, good
str( sub.s[ k.orf, 1:2] ) # test the selection, good
summary(stein);
sub.s[ is.na( sub.s) ] = 0;
sub.s
str( sub.s );
sub.s[ k.orf, 1:2] # test the selection, good
train = sub.s[ k.orf, 1:2] # test the selection, good
train = sub.s[ k.orf, 1:2] # test the selection, good
train2 = train[ ! is.na(train) ] 
train
train2
str(train2);
str(train);
train2 = train[ ! is.na(train[,2]) ] 
train
train = sub.s[ k.orf, ] # test the selection, good
train
train2 = train[ ! is.na(train[,2]) ] 
train[,2]
train2 = train[ ! is.na(train[,2]), ] 
train2
str(train);
str(train2);
tb
tb$score[ k.orf ] ;
row.names(tb) = tb$orf;
tb$score[ k.orf ] ;
tb
tb = read.table("kaeberlein.short.tab" );
names(tb) = c("orf", "name", "arls", "ln2Ratio", "score");
k.orf = as.character( tb$orf );
row.names(tb) = tb$orf;
train = sub.s[ k.orf, ] # test the selection, good
train
str(train);
tb$score
###svm prediction
y = factor( tb$score )
x = train[,seq(1,10)]
model = svm( x, y);
model
    pred <- predict(model, x)
pred
model
  table( pred, y)  #Ha, this is 100% correct.
help(svm);
#decide to use 10% as cutoff 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.1 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  #Ha, this is 100% correct.
 pred.gasch = predict(model, gpcs[,1:43]);
summary(pred.gasch); #shit 4573 decrease genes, only 5 
increase genes from training set.
####################loose the different cutoff values
#decide to use 10% as cutoff 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1 ] = "increase";
tb$score[ (tb$arls/26.5)<1 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  
 pred.stein = predict(model, sub.s);
summary(pred.stein); 
#decide to use 10% as cutoff 
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.05 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  
 pred.stein = predict(model, sub.s);
summary(pred.stein); 
sub.s
sub.s[1:5,]
table( pred, y)  
 pred.stein = predict(model, sub.s);
model
str(sub.s);
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.1 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  
 pred.stein = predict(model, sub.s);
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.08 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.075 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y)  
 pred.stein = predict(model, sub.s);
tb$score = "moderate";
tb$score[ (tb$arls/26.5)>1.07 ] = "increase";
tb$score[ (tb$arls/26.5)<0.9 ] = "decrease";
factor(tb$score);
y = factor( tb$score )
model = svm( x, y);
pred <- predict(model, x)
table( pred, y) 
pred
y
x
str(x);
 pred.stein = predict(model, sub.s[,seq(1,10)] );
summary(pred.stein);
